{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10170850,"sourceType":"datasetVersion","datasetId":6281493}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import pearsonr\nfrom scipy import stats\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport os\n\ndef read_data(filename):\n    with open(filename, 'rb') as f:\n        x = pickle._Unpickler(f)\n        x.encoding = 'latin1'\n        data = x.load()\n    return data\n\n# List of participant file names\nfiles = [f\"{i:02}\" for i in range(1, 33)]\n\nlabels = []\ndata = []\n\nbase_path = \"/kaggle/input/deap-dataset/deap-dataset/data_preprocessed_python/\"\n\nfor i in files:\n    file_path = os.path.join(base_path, f\"s{i}.dat\")\n    d = read_data(file_path)\n    labels.append(d['labels'])\n    data.append(d['data'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T14:50:49.618745Z","iopub.execute_input":"2025-09-24T14:50:49.619003Z","iopub.status.idle":"2025-09-24T14:51:07.110789Z","shell.execute_reply.started":"2025-09-24T14:50:49.618976Z","shell.execute_reply":"2025-09-24T14:51:07.109901Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## VAE model","metadata":{}},{"cell_type":"code","source":"\n\nclass ConditionedVAE(nn.Module):\n    def __init__(self, input_dim=2880, emotion_dim=4, latent_dim=128, hidden_dim=512):\n        super(ConditionedVAE, self).__init__()\n        \n        self.input_dim = input_dim\n        self.emotion_dim = emotion_dim\n        self.latent_dim = latent_dim\n        \n        # encoder: EEG + emos\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim + emotion_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim, hidden_dim//2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim//2, hidden_dim//4),\n            nn.ReLU()\n        )\n        \n        self.fc_mu = nn.Linear(hidden_dim//4, latent_dim)\n        self.fc_logvar = nn.Linear(hidden_dim//4, latent_dim)\n        \n        # Decoder: latent space + emotions -> EEG\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim + emotion_dim, hidden_dim//4),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim//4, hidden_dim//2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim//2, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim, input_dim)\n        )\n    \n    def encode(self, x, emotions):\n        x_cond = torch.cat([x, emotions], dim=1)\n        h = self.encoder(x_cond)\n        mu = self.fc_mu(h)\n        logvar = self.fc_logvar(h)\n        return mu, logvar\n    \n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n    \n    def decode(self, z, emotions):\n        z_cond = torch.cat([z, emotions], dim=1)\n        return self.decoder(z_cond)\n    \n    def forward(self, x, emotions):\n        mu, logvar = self.encode(x, emotions)\n        z = self.reparameterize(mu, logvar)\n        recon_x = self.decode(z, emotions)\n        return recon_x, mu, logvar","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:41.256224Z","iopub.execute_input":"2025-09-23T22:11:41.256544Z","iopub.status.idle":"2025-09-23T22:11:41.266144Z","shell.execute_reply.started":"2025-09-23T22:11:41.256522Z","shell.execute_reply":"2025-09-23T22:11:41.265423Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_data(X, y, method='standardize'):\n    \"\"\"\n    Preprocess EEG data and emotion labels\n    \"\"\"\n    # Flatten EEG data\n    X_flat = X.reshape(X.shape[0], -1)\n    \n    if method == 'standardize':\n        scaler_X = StandardScaler()\n        X_processed = scaler_X.fit_transform(X_flat)\n    elif method == 'minmax':\n        scaler_X = MinMaxScaler(feature_range=(-1, 1))\n        X_processed = scaler_X.fit_transform(X_flat)\n    \n    # Normalize emotion labels\n    scaler_y = StandardScaler()\n    y_processed = scaler_y.fit_transform(y)\n    \n    return X_processed, y_processed, scaler_X, scaler_y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"#new data generation function\ndef generate_new_samples(model, emotion_conditions, scaler_X, scaler_y, num_samples=10):\n    \"\"\"\n    Generate new EEG samples given emotion conditions\n    \"\"\"\n    device = next(model.parameters()).device\n    model.eval()\n    \n    # Normalize emotion conditions\n    emotion_normalized = scaler_y.transform(emotion_conditions)\n    emotion_tensor = torch.FloatTensor(emotion_normalized).to(device)\n    \n    with torch.no_grad():\n        # Sample from prior\n        z = torch.randn(num_samples, model.latent_dim).to(device)\n        \n        # Decode with emotion conditions\n        generated = model.decode(z, emotion_tensor)\n        generated_np = generated.cpu().numpy()\n        \n        # Convert back to original scale\n        generated_original = scaler_X.inverse_transform(generated_np)\n        generated_shaped = generated_original.reshape(num_samples, 32, 90)\n    \n    return generated_shaped","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def vae_loss_function(recon_x, x, mu, logvar, beta=1.0):\n    \"\"\"\n    VAE loss = Reconstruction Loss + KL Divergence\n    \"\"\"\n    # Reconstruction loss (MSE)\n    recon_loss = nn.MSELoss(reduction='sum')(recon_x, x)\n    \n    # KL divergence\n    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    \n    return recon_loss + beta * kl_loss, recon_loss, kl_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef train_vae_with_evaluation(X, y, num_epochs=200, batch_size=32, lr=0.001, \n                             latent_dim=128, beta=1.0, test_size=0.2):\n    \"\"\"\n    Complete VAE training with comprehensive evaluation\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Preprocess data\n    print(\"Preprocessing data...\")\n    X_processed, y_processed, scaler_X, scaler_y = preprocess_data(X, y)\n    \n    # Split data into train/test\n    X_train, X_test, y_train, y_test = train_test_split(\n        X_processed, y_processed, test_size=test_size, random_state=42, stratify=None\n    )\n    \n    print(f\"Train set: {X_train.shape[0]} samples\")\n    print(f\"Test set: {X_test.shape[0]} samples\")\n    \n    # Convert to tensors\n    X_train_tensor = torch.FloatTensor(X_train).to(device)\n    y_train_tensor = torch.FloatTensor(y_train).to(device)\n    X_test_tensor = torch.FloatTensor(X_test).to(device)\n    y_test_tensor = torch.FloatTensor(y_test).to(device)\n    \n    # Create datasets and dataloaders\n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n     \n    # Initialize model\n    model = ConditionedVAE(\n        input_dim=X_processed.shape[1], \n        emotion_dim=y_processed.shape[1], \n        latent_dim=latent_dim\n    ).to(device)\n    \n    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    \n    # Optimizer\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, factor=0.5)\n    \n    # Training history\n    train_losses = []\n    test_losses = []\n    train_recon_losses = []\n    train_kl_losses = []\n    \n    print(\"Starting VAE training...\")\n    \n    best_test_loss = float('inf')\n    patience_counter = 0\n    patience = 50\n      for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss = 0\n        train_recon_loss = 0\n        train_kl_loss = 0\n        \n        for batch_idx, (data, emotions) in enumerate(train_loader):\n            optimizer.zero_grad()\n            \n            recon_data, mu, logvar = model(data, emotions)\n            loss, recon_loss, kl_loss = vae_loss_function(recon_data, data, mu, logvar, beta)\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            train_recon_loss += recon_loss.item()\n            train_kl_loss += kl_loss.item()\n        \n        # Evaluation phase\n        model.eval()\n        test_loss = 0\n          \n        with torch.no_grad():\n            for data, emotions in test_loader:\n                recon_data, mu, logvar = model(data, emotions)\n                loss, _, _ = vae_loss_function(recon_data, data, mu, logvar, beta)\n                test_loss += loss.item()\n        \n        # Calculate average losses\n        avg_train_loss = train_loss / len(train_loader.dataset)\n        avg_test_loss = test_loss / len(test_loader.dataset)\n        avg_recon_loss = train_recon_loss / len(train_loader.dataset)\n        avg_kl_loss = train_kl_loss / len(train_loader.dataset)\n        \n        # Store losses\n        train_losses.append(avg_train_loss)\n        test_losses.append(avg_test_loss)\n        train_recon_losses.append(avg_recon_loss)\n        train_kl_losses.append(avg_kl_loss)\n        \n        # Learning rate scheduling\n        scheduler.step(avg_test_loss)\n        \n        # Early stopping\n        if avg_test_loss < best_test_loss:\n            best_test_loss = avg_test_loss\n            patience_counter = 0\n            # Save best model\n            torch.save(model.state_dict(), 'best_vae_model.pth')\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n        \n        # Print progress\n        if epoch % 20 == 0 or epoch == num_epochs - 1:\n            print(f'Epoch [{epoch}/{num_epochs}] | '\n                  f'Train Loss: {avg_train_loss:.4f} | '\n                  f'Test Loss: {avg_test_loss:.4f} | '\n                  f'Recon: {avg_recon_loss:.4f} | '\n                  f'KL: {avg_kl_loss:.4f}')\n    \n    # Load best model\n    model.load_state_dict(torch.load('best_vae_model.pth'))\n    \n    return model, train_losses, test_losses, train_recon_losses, train_kl_losses, scaler_X, scaler_y, X_test, y_test\n\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"def calculate_reconstruction_metrics(original, reconstructed):\n    \"\"\"\n    Calculate various reconstruction accuracy metrics\n    \"\"\"\n    # Flatten arrays for calculation\n    orig_flat = original.flatten()\n    recon_flat = reconstructed.flatten()\n    \n    # Mean Squared Error\n    mse = mean_squared_error(orig_flat, recon_flat)\n    \n    # Root Mean Squared Error\n    rmse = np.sqrt(mse)\n    \n    # Mean Absolute Error\n    mae = mean_absolute_error(orig_flat, recon_flat)\n    \n    # R-squared score\n    r2 = r2_score(orig_flat, recon_flat)\n    \n    # Pearson correlation\n    correlation, p_value = pearsonr(orig_flat, recon_flat)\n    \n    # Signal-to-Noise Ratio\n    signal_power = np.mean(orig_flat ** 2)\n    noise_power = np.mean((orig_flat - recon_flat) ** 2)\n    snr = 10 * np.log10(signal_power / noise_power) if noise_power > 0 else float('inf')\n    \n    # Percentage of variance explained\n    variance_explained = 1 - (np.var(orig_flat - recon_flat) / np.var(orig_flat))\n    \n    return {\n        'MSE': mse,\n        'RMSE': rmse,\n        'MAE': mae,\n        'R2': r2,\n        'Correlation': correlation,\n        'P_value': p_value,\n        'SNR_dB': snr,\n        'Variance_Explained': variance_explained\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def comprehensive_evaluation(model, X_test, y_test, scaler_X, original_shape=(32, 90)):\n    \"\"\"\n    Comprehensive evaluation of trained VAE\n    \"\"\"\n    device = next(model.parameters()).device\n    model.eval()\n    \n    # Convert test data to tensors\n    X_test_tensor = torch.FloatTensor(X_test).to(device)\n    y_test_tensor = torch.FloatTensor(y_test).to(device)\n    \n    with torch.no_grad():\n        # Get reconstructions\n        recon_data, mu, logvar = model(X_test_tensor, y_test_tensor)\n        recon_data_np = recon_data.cpu().numpy()\n    \n    # Calculate reconstruction metrics\n    metrics = calculate_reconstruction_metrics(X_test, recon_data_np)\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"VAE RECONSTRUCTION ACCURACY METRICS\")\n    print(\"=\"*50)\n    print(f\"Mean Squared Error (MSE):     {metrics['MSE']:.6f}\")\n    print(f\"Root Mean Squared Error:      {metrics['RMSE']:.6f}\")\n    print(f\"Mean Absolute Error:          {metrics['MAE']:.6f}\")\n    print(f\"R-squared Score:              {metrics['R2']:.4f}\")\n    print(f\"Pearson Correlation:          {metrics['Correlation']:.4f} (p={metrics['P_value']:.4e})\")\n    print(f\"Signal-to-Noise Ratio:        {metrics['SNR_dB']:.2f} dB\")\n    print(f\"Variance Explained:           {metrics['Variance_Explained']:.4f}\")\n    print(\"=\"*50)\n    \n    # Convert back to original shape for visualization\n    original_reshaped = scaler_X.inverse_transform(X_test).reshape(-1, *original_shape)\n    recon_reshaped = scaler_X.inverse_transform(recon_data_np).reshape(-1, *original_shape)\n    \n    return metrics, original_reshaped, recon_reshaped, mu.cpu().numpy(), logvar.cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plotting","metadata":{}},{"cell_type":"code","source":"def plot_training_results(train_losses, test_losses, train_recon_losses, train_kl_losses):\n    \"\"\"\n    Plot training curves and losses\n    \"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # Total loss\n    axes[0,0].plot(train_losses, label='Train Loss', alpha=0.8)\n    axes[0,0].plot(test_losses, label='Test Loss', alpha=0.8)\n    axes[0,0].set_xlabel('Epoch')\n    axes[0,0].set_ylabel('Total Loss')\n    axes[0,0].set_title('Training and Test Loss')\n    axes[0,0].legend()\n    axes[0,0].grid(True, alpha=0.3)\n    \n    # Reconstruction and KL losses\n    axes[0,1].plot(train_recon_losses, label='Reconstruction Loss', color='blue', alpha=0.8)\n    axes[0,1].set_xlabel('Epoch')\n    axes[0,1].set_ylabel('Reconstruction Loss', color='blue')\n    axes[0,1].tick_params(axis='y', labelcolor='blue')\n    axes[0,1].grid(True, alpha=0.3)\n    \n    ax2 = axes[0,1].twinx()\n    ax2.plot(train_kl_losses, label='KL Divergence', color='red', alpha=0.8)\n    ax2.set_ylabel('KL Divergence', color='red')\n    ax2.tick_params(axis='y', labelcolor='red')\n    axes[0,1].set_title('Reconstruction vs KL Loss')\n    \n    # Loss distribution\n    axes[1,0].hist(train_losses[-50:], bins=20, alpha=0.7, label='Recent Train Loss')\n    axes[1,0].hist(test_losses[-50:], bins=20, alpha=0.7, label='Recent Test Loss')\n    axes[1,0].set_xlabel('Loss Value')\n    axes[1,0].set_ylabel('Frequency')\n    axes[1,0].set_title('Recent Loss Distribution')\n    axes[1,0].legend()\n    \n    # Learning curve smoothed\n    window = 10\n    if len(train_losses) > window:\n        train_smooth = np.convolve(train_losses, np.ones(window)/window, mode='valid')\n        test_smooth = np.convolve(test_losses, np.ones(window)/window, mode='valid')\n        axes[1,1].plot(train_smooth, label=f'Train Loss (smoothed)', alpha=0.8)\n        axes[1,1].plot(test_smooth, label=f'Test Loss (smoothed)', alpha=0.8)\n        axes[1,1].set_xlabel('Epoch')\n        axes[1,1].set_ylabel('Smoothed Loss')\n        axes[1,1].set_title('Smoothed Learning Curves')\n        axes[1,1].legend()\n        axes[1,1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_reconstruction_comparison(original, reconstructed, num_samples=3):\n    \"\"\"\n    Visualize original vs reconstructed EEG data\n    \"\"\"\n    fig, axes = plt.subplots(num_samples, 2, figsize=(15, 4*num_samples))\n    \n    for i in range(num_samples):\n        # Original EEG\n        im1 = axes[i,0].imshow(original[i], aspect='auto', cmap='viridis')\n        axes[i,0].set_title(f'Original EEG Sample {i+1}')\n        axes[i,0].set_xlabel('Time')\n        axes[i,0].set_ylabel('Channels')\n        plt.colorbar(im1, ax=axes[i,0])\n        \n        # Reconstructed EEG\n        im2 = axes[i,1].imshow(reconstructed[i], aspect='auto', cmap='viridis')\n        axes[i,1].set_title(f'Reconstructed EEG Sample {i+1}')\n        axes[i,1].set_xlabel('Time')\n        axes[i,1].set_ylabel('Channels')\n        plt.colorbar(im2, ax=axes[i,1])\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main_vae_training(X, y):\n    \"\"\"\n    Complete VAE training pipeline with all metrics\n    \"\"\"\n    print(f\"Starting VAE training with data shape: X{X.shape}, y{y.shape}\")\n    \n    # Train the VAE\n    model, train_losses, test_losses, train_recon_losses, train_kl_losses, scaler_X, scaler_y, X_test, y_test = train_vae_with_evaluation(\n        X, y, num_epochs=250, batch_size=32, lr=0.001, latent_dim=128, beta=1.0\n    )\n    \n    # Plot training results\n    plot_training_results(train_losses, test_losses, train_recon_losses, train_kl_losses)\n    \n    # Comprehensive evaluation\n    metrics, original_samples, recon_samples, mu, logvar = comprehensive_evaluation(\n        model, X_test, y_test, scaler_X\n    )\n    \n    # Visualize reconstructions\n    plot_reconstruction_comparison(original_samples, recon_samples, num_samples=3)\n    \n    # Generate new samples\n    test_emotions = [[5, 5, 5, 5], [7, 3, 6, 4], [2, 8, 3, 7]]  # Different emotion conditions\n    generated_samples = generate_new_samples(model, test_emotions, scaler_X, scaler_y, len(test_emotions))\n    \n    print(f\"\\nGenerated {len(generated_samples)} new EEG samples with custom emotion conditions\")\n    \n    return model, metrics, generated_samples, scaler_X, scaler_y\n\nmodel, metrics, generated_samples, scaler_X, scaler_y = main_vae_training(X, y)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}