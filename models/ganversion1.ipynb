{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10170850,"sourceType":"datasetVersion","datasetId":6281493}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import pearsonr, wasserstein_distance\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set device and random seeds\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:41.256224Z","iopub.execute_input":"2025-09-23T22:11:41.256544Z","iopub.status.idle":"2025-09-23T22:11:41.266144Z","shell.execute_reply.started":"2025-09-23T22:11:41.256522Z","shell.execute_reply":"2025-09-23T22:11:41.265423Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"class ImprovedDiscriminator(nn.Module):\n    def __init__(self):\n        super(ImprovedDiscriminator, self).__init__()\n        \n        from torch.nn.utils import spectral_norm\n        \n        self.model = nn.Sequential(\n            spectral_norm(nn.Linear(num_features + num_emotion_dims, 1024)),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            \n            spectral_norm(nn.Linear(1024, 512)),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            \n            spectral_norm(nn.Linear(512, 256)),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n            \n            spectral_norm(nn.Linear(256, 128)),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Linear(128, 1)\n            \n        )\n        \n        self.apply(self._init_weights)\n    \n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.zeros_(m.bias)\n\n    def forward(self, eeg_data, emotion_labels):\n        input_tensor = torch.cat([eeg_data, emotion_labels], dim=1)\n        return self.model(input_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:41.516762Z","iopub.execute_input":"2025-09-23T22:11:41.517111Z","iopub.status.idle":"2025-09-23T22:11:41.525620Z","shell.execute_reply.started":"2025-09-23T22:11:41.517089Z","shell.execute_reply":"2025-09-23T22:11:41.524940Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class ImprovedGenerator(nn.Module):\n    def __init__(self):\n        super(ImprovedGenerator, self).__init__()\n        \n        # Use spectral normalization for training stability\n        from torch.nn.utils import spectral_norm\n        \n        self.input_layer = nn.Linear(nz + num_emotion_dims, 256)\n        \n        # Residual blocks for better gradient flow\n        self.block1 = nn.Sequential(\n            spectral_norm(nn.Linear(256, 512)),\n            nn.BatchNorm1d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2)\n        )\n        \n        self.block2 = nn.Sequential(\n            spectral_norm(nn.Linear(512, 1024)),\n            nn.BatchNorm1d(1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2)\n        )\n        \n        self.block3 = nn.Sequential(\n            spectral_norm(nn.Linear(1024, 2048)),\n            nn.BatchNorm1d(2048),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2)\n        )\n        \n        self.output_layer = nn.Linear(2048, num_features)\n        \n        # Initialize weights properly\n        self.apply(self._init_weights)\n    \n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.zeros_(m.bias)\n    \n    def forward(self, noise, emotion_labels):\n        x = torch.cat([noise, emotion_labels], dim=1)\n        x = torch.relu(self.input_layer(x))\n        \n        # Residual connections where possible\n        x1 = self.block1(x)\n        x2 = self.block2(x1)\n        x3 = self.block3(x2)\n        \n        # Output without activation - let it learn the right range\n        return self.output_layer(x3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:42.545318Z","iopub.execute_input":"2025-09-23T22:11:42.545588Z","iopub.status.idle":"2025-09-23T22:11:42.553073Z","shell.execute_reply.started":"2025-09-23T22:11:42.545567Z","shell.execute_reply":"2025-09-23T22:11:42.552256Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def inception_score(generated_samples, discriminator, emotion_labels, splits=10):\n    \"\"\"\n    Calculate Inception Score for generated samples\n    \"\"\"\n    discriminator.eval()\n    scores = []\n    \n    with torch.no_grad():\n        for i in range(splits):\n            part = generated_samples[i * len(generated_samples) // splits:(i + 1) * len(generated_samples) // splits]\n            part_emotions = emotion_labels[i * len(emotion_labels) // splits:(i + 1) * len(emotion_labels) // splits]\n            \n            part_tensor = torch.FloatTensor(part).to(device)\n            part_emotions_tensor = torch.FloatTensor(part_emotions).to(device)\n            \n            pred = torch.sigmoid(discriminator(part_tensor, part_emotions_tensor))\n            \n            # Calculate score\n            p_y = pred.mean(dim=0, keepdim=True)\n            scores.append(torch.exp(torch.mean(pred * (torch.log(pred) - torch.log(p_y)))))\n    \n    return torch.mean(torch.stack(scores)).item(), torch.std(torch.stack(scores)).item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:42.712999Z","iopub.execute_input":"2025-09-23T22:11:42.713314Z","iopub.status.idle":"2025-09-23T22:11:42.719648Z","shell.execute_reply.started":"2025-09-23T22:11:42.713292Z","shell.execute_reply":"2025-09-23T22:11:42.719001Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def improved_preprocess_for_gan(X, y):\n    \"\"\"\n    Better preprocessing for GAN training\n    \"\"\"\n    # Flatten X\n    X_flat = X.reshape(X.shape[0], -1)  # (samples, 2880)\n    \n    # Use StandardScaler for more stable training\n    scaler_X = StandardScaler()\n    X_normalized = scaler_X.fit_transform(X_flat)\n    \n    # Normalize emotion labels properly\n    scaler_y = StandardScaler()\n    y_normalized = scaler_y.fit_transform(y)\n    \n    return X_normalized, y_normalized, scaler_X, scaler_y\n\n# Wasserstein Loss with Gradient Penalty (more stable than BCE)\ndef gradient_penalty(discriminator, real_data, fake_data, emotion_labels, lambda_gp=10):\n    \"\"\"\n    Calculate gradient penalty for WGAN-GP\n    \"\"\"\n    batch_size = real_data.size(0)\n    alpha = torch.rand(batch_size, 1).to(device)\n    alpha = alpha.expand_as(real_data)\n    \n    interpolated = alpha * real_data + (1 - alpha) * fake_data\n    interpolated.requires_grad_(True)\n    \n    # Calculate discriminator output for interpolated data\n    d_interpolated = discriminator(interpolated, emotion_labels)\n    \n    # Calculate gradients\n    gradients = torch.autograd.grad(\n        outputs=d_interpolated,\n        inputs=interpolated,\n        grad_outputs=torch.ones_like(d_interpolated),\n        create_graph=True,\n        retain_graph=True,\n        only_inputs=True\n    )[0]\n    \n    gradients = gradients.view(batch_size, -1)\n    gradient_norm = gradients.norm(2, dim=1)\n    penalty = lambda_gp * ((gradient_norm - 1) ** 2).mean()\n    \n    return penalty\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:43.944568Z","iopub.execute_input":"2025-09-23T22:11:43.944836Z","iopub.status.idle":"2025-09-23T22:11:43.950980Z","shell.execute_reply.started":"2025-09-23T22:11:43.944816Z","shell.execute_reply":"2025-09-23T22:11:43.950277Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def calculate_generation_metrics(real_data, fake_data):\n    \"\"\"\n    Calculate comprehensive metrics for generated vs real data\n    \"\"\"\n    # Flatten for calculations\n    real_flat = real_data.flatten()\n    fake_flat = fake_data.flatten()\n    \n    metrics = {}\n    \n    # Distribution similarity\n    metrics['wasserstein_distance'] = wasserstein_distance(real_flat, fake_flat)\n    metrics['ks_statistic'], metrics['ks_p_value'] = stats.ks_2samp(real_flat, fake_flat)\n    \n    # Statistical moments\n    metrics['mean_diff'] = abs(np.mean(real_flat) - np.mean(fake_flat))\n    metrics['std_diff'] = abs(np.std(real_flat) - np.std(fake_flat))\n    metrics['skewness_diff'] = abs(stats.skew(real_flat) - stats.skew(fake_flat))\n    metrics['kurtosis_diff'] = abs(stats.kurtosis(real_flat) - stats.kurtosis(fake_flat))\n    \n    # Correlation with real data patterns\n    if len(real_flat) == len(fake_flat):\n        correlation, p_value = pearsonr(real_flat, fake_flat)\n        metrics['correlation'] = correlation\n        metrics['correlation_p_value'] = p_value\n    \n    # MSE and MAE\n    if real_data.shape == fake_data.shape:\n        metrics['mse'] = mean_squared_error(real_flat, fake_flat)\n        metrics['mae'] = mean_absolute_error(real_flat, fake_flat)\n        metrics['rmse'] = np.sqrt(metrics['mse'])\n    \n    # Frequency domain analysis\n    real_fft = np.fft.fft(real_data.reshape(-1, 32, 90), axis=-1)\n    fake_fft = np.fft.fft(fake_data.reshape(-1, 32, 90), axis=-1)\n    \n    real_power = np.mean(np.abs(real_fft) ** 2)\n    fake_power = np.mean(np.abs(fake_fft) ** 2)\n    metrics['power_spectrum_diff'] = abs(real_power - fake_power) / real_power\n    \n    return metrics\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:47.778769Z","iopub.execute_input":"2025-09-23T22:11:47.779043Z","iopub.status.idle":"2025-09-23T22:11:47.785984Z","shell.execute_reply.started":"2025-09-23T22:11:47.779024Z","shell.execute_reply":"2025-09-23T22:11:47.785226Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"\n\n# IMPROVED Hyperparameters\nnz = 128  # Increased noise dimension for more diversity\nnum_features = 2880  # 32 * 90 flattened\nnum_emotion_dims = 4\nlr_g = 0.0001  # Lower learning rate for generator (more stable)\nlr_d = 0.0002  # Higher learning rate for discriminator\nbeta1 = 0.5\nbatch_size = 32\nnum_epochs = 300  # More epochs for better convergence\n\n\n\n# IMPROVED training function with comprehensive evaluation\ndef train_improved_gan(X, y, num_epochs=300, use_wgan_gp=True):\n    \"\"\"\n    Enhanced GAN training with evaluation metrics\n    \"\"\"\n    print(f\"Training Enhanced GAN on data: X{X.shape}, y{y.shape}\")\n    \n    # Split data for evaluation\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    # Preprocess data\n    X_train_proc, y_train_proc, scaler_X, scaler_y = improved_preprocess_for_gan(X_train, y_train)\n    X_test_proc, y_test_proc, _, _ = improved_preprocess_for_gan(X_test, y_test)\n    \n    # Convert to tensors\n    X_train_tensor = torch.FloatTensor(X_train_proc).to(device)\n    y_train_tensor = torch.FloatTensor(y_train_proc).to(device)\n    X_test_tensor = torch.FloatTensor(X_test_proc).to(device)\n    y_test_tensor = torch.FloatTensor(y_test_proc).to(device)\n    \n    # Create dataloader\n    dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n    \n    # Initialize improved networks\n    generator = ImprovedGenerator().to(device)\n    discriminator = ImprovedDiscriminator().to(device)\n    \n    print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n    print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n    \n    # Optimizers with different learning rates\n    optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(beta1, 0.999))\n    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(beta1, 0.999))\n    \n    # Learning rate schedulers\n    scheduler_G = optim.lr_scheduler.ExponentialLR(optimizer_G, gamma=0.995)\n    scheduler_D = optim.lr_scheduler.ExponentialLR(optimizer_D, gamma=0.995)\n    \n    # Loss function\n    if use_wgan_gp:\n        criterion = None  # Use Wasserstein loss\n    else:\n        criterion = nn.BCEWithLogitsLoss()\n    \n    # Training history\n    G_losses = []\n    D_losses = []\n    evaluation_history = []\n    \n    print(\"Starting Enhanced GAN Training...\")\n    \n    for epoch in range(num_epochs):\n        epoch_g_loss = 0\n        epoch_d_loss = 0\n        \n        for i, (real_data, real_labels) in enumerate(dataloader):\n            batch_size_current = real_data.size(0)\n            \n            # ---------------------\n            # Train Discriminator (more frequently for stability)\n            # ---------------------\n            for _ in range(2):  # Train D twice per G training\n                optimizer_D.zero_grad()\n                \n                if use_wgan_gp:\n                    # Wasserstein loss with gradient penalty\n                    # Real data\n                    d_real = discriminator(real_data, real_labels).mean()\n                    \n                    # Fake data\n                    noise = torch.randn(batch_size_current, nz).to(device)\n                    fake_data = generator(noise, real_labels).detach()\n                    d_fake = discriminator(fake_data, real_labels).mean()\n                    \n                    # Gradient penalty\n                    gp = gradient_penalty(discriminator, real_data, fake_data, real_labels)\n                    \n                    # Wasserstein loss\n                    loss_D = d_fake - d_real + gp\n                else:\n                    # Standard GAN loss\n                    real_labels_disc = torch.ones(batch_size_current, 1).to(device)\n                    fake_labels_disc = torch.zeros(batch_size_current, 1).to(device)\n                    \n                    # Real data\n                    output_real = discriminator(real_data, real_labels)\n                    loss_D_real = criterion(output_real, real_labels_disc)\n                    \n                    # Fake data\n                    noise = torch.randn(batch_size_current, nz).to(device)\n                    fake_data = generator(noise, real_labels).detach()\n                    output_fake = discriminator(fake_data, real_labels)\n                    loss_D_fake = criterion(output_fake, fake_labels_disc)\n                    \n                    loss_D = (loss_D_real + loss_D_fake) / 2\n                \n                loss_D.backward()\n                torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 1.0)\n                optimizer_D.step()\n            \n            # -----------------\n            # Train Generator\n            # -----------------\n            optimizer_G.zero_grad()\n            \n            noise = torch.randn(batch_size_current, nz).to(device)\n            fake_data = generator(noise, real_labels)\n            \n            if use_wgan_gp:\n                # Wasserstein loss for generator\n                loss_G = -discriminator(fake_data, real_labels).mean()\n            else:\n                # Standard GAN loss\n                output_fake = discriminator(fake_data, real_labels)\n                loss_G = criterion(output_fake, torch.ones(batch_size_current, 1).to(device))\n            \n            loss_G.backward()\n            torch.nn.utils.clip_grad_norm_(generator.parameters(), 1.0)\n            optimizer_G.step()\n            \n            epoch_g_loss += loss_G.item()\n            epoch_d_loss += loss_D.item()\n        \n        # Update learning rates\n        if epoch > 50:\n            scheduler_G.step()\n            scheduler_D.step()\n        \n        # Record losses\n        avg_g_loss = epoch_g_loss / len(dataloader)\n        avg_d_loss = epoch_d_loss / len(dataloader)\n        G_losses.append(avg_g_loss)\n        D_losses.append(avg_d_loss)\n        \n        # Comprehensive evaluation every 25 epochs\n        if epoch % 25 == 0:\n            print(f'Epoch [{epoch}/{num_epochs}] | G Loss: {avg_g_loss:.4f} | D Loss: {avg_d_loss:.4f}')\n            \n            # Generate samples for evaluation\n            generator.eval()\n            with torch.no_grad():\n                test_noise = torch.randn(len(X_test), nz).to(device)\n                generated_test = generator(test_noise, y_test_tensor)\n                generated_test_np = generated_test.cpu().numpy()\n                \n                # Convert back to original scale\n                generated_original = scaler_X.inverse_transform(generated_test_np)\n                generated_shaped = generated_original.reshape(-1, 32, 90)\n                \n                # Calculate metrics\n                metrics = calculate_generation_metrics(X_test, generated_shaped)\n                evaluation_history.append({\n                    'epoch': epoch,\n                    'metrics': metrics,\n                    'g_loss': avg_g_loss,\n                    'd_loss': avg_d_loss\n                })\n                \n                print(f\"  Wasserstein Distance: {metrics['wasserstein_distance']:.4f}\")\n                print(f\"  Mean Difference: {metrics['mean_diff']:.4f}\")\n                print(f\"  Power Spectrum Diff: {metrics['power_spectrum_diff']:.4f}\")\n            \n            generator.train()\n    \n    return generator, discriminator, G_losses, D_losses, evaluation_history, scaler_X, scaler_y\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:48.817424Z","iopub.execute_input":"2025-09-23T22:11:48.817688Z","iopub.status.idle":"2025-09-23T22:11:48.835950Z","shell.execute_reply.started":"2025-09-23T22:11:48.817669Z","shell.execute_reply":"2025-09-23T22:11:48.835228Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"\n# Comprehensive visualization functions\ndef plot_comprehensive_results(G_losses, D_losses, evaluation_history, real_samples, fake_samples):\n    \"\"\"\n    Create comprehensive visualization of GAN results\n    \"\"\"\n    fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n    \n    # 1. Training losses\n    axes[0,0].plot(G_losses, label='Generator Loss', alpha=0.8)\n    axes[0,0].plot(D_losses, label='Discriminator Loss', alpha=0.8)\n    axes[0,0].set_xlabel('Epoch')\n    axes[0,0].set_ylabel('Loss')\n    axes[0,0].set_title('Training Losses')\n    axes[0,0].legend()\n    axes[0,0].grid(True, alpha=0.3)\n    \n    # 2. Wasserstein distance over time\n    epochs = [eval_data['epoch'] for eval_data in evaluation_history]\n    wasserstein_dists = [eval_data['metrics']['wasserstein_distance'] for eval_data in evaluation_history]\n    axes[0,1].plot(epochs, wasserstein_dists, 'o-', color='red', alpha=0.8)\n    axes[0,1].set_xlabel('Epoch')\n    axes[0,1].set_ylabel('Wasserstein Distance')\n    axes[0,1].set_title('Distribution Similarity Over Time')\n    axes[0,1].grid(True, alpha=0.3)\n    \n    # 3. Statistical moments comparison\n    mean_diffs = [eval_data['metrics']['mean_diff'] for eval_data in evaluation_history]\n    std_diffs = [eval_data['metrics']['std_diff'] for eval_data in evaluation_history]\n    axes[0,2].plot(epochs, mean_diffs, 'o-', label='Mean Difference', alpha=0.8)\n    axes[0,2].plot(epochs, std_diffs, 's-', label='Std Difference', alpha=0.8)\n    axes[0,2].set_xlabel('Epoch')\n    axes[0,2].set_ylabel('Difference')\n    axes[0,2].set_title('Statistical Moments Differences')\n    axes[0,2].legend()\n    axes[0,2].grid(True, alpha=0.3)\n    \n    # 4. Data distribution comparison\n    axes[1,0].hist(real_samples.flatten(), bins=50, alpha=0.7, label='Real Data', density=True)\n    axes[1,0].hist(fake_samples.flatten(), bins=50, alpha=0.7, label='Generated Data', density=True)\n    axes[1,0].set_xlabel('Feature Values')\n    axes[1,0].set_ylabel('Density')\n    axes[1,0].set_title('Data Distribution Comparison')\n    axes[1,0].legend()\n    \n    # 5. Q-Q Plot\n    real_flat_sorted = np.sort(real_samples.flatten())\n    fake_flat_sorted = np.sort(fake_samples.flatten())\n    min_len = min(len(real_flat_sorted), len(fake_flat_sorted))\n    axes[1,1].scatter(real_flat_sorted[:min_len], fake_flat_sorted[:min_len], alpha=0.5, s=1)\n    axes[1,1].plot([real_flat_sorted.min(), real_flat_sorted.max()], \n                   [real_flat_sorted.min(), real_flat_sorted.max()], 'r--')\n    axes[1,1].set_xlabel('Real Data Quantiles')\n    axes[1,1].set_ylabel('Generated Data Quantiles')\n    axes[1,1].set_title('Q-Q Plot')\n    \n    # 6. Power spectrum comparison\n    real_fft = np.fft.fft(real_samples[:100].reshape(-1, 90), axis=-1)\n    fake_fft = np.fft.fft(fake_samples[:100].reshape(-1, 90), axis=-1)\n    \n    freqs = np.fft.fftfreq(90)[:45]  # Only positive frequencies\n    real_power = np.mean(np.abs(real_fft[:, :45]) ** 2, axis=0)\n    fake_power = np.mean(np.abs(fake_fft[:, :45]) ** 2, axis=0)\n    \n    axes[1,2].plot(freqs, real_power, label='Real Data', alpha=0.8)\n    axes[1,2].plot(freqs, fake_power, label='Generated Data', alpha=0.8)\n    axes[1,2].set_xlabel('Frequency')\n    axes[1,2].set_ylabel('Power')\n    axes[1,2].set_title('Power Spectrum Comparison')\n    axes[1,2].legend()\n    \n    # 7. Sample EEG comparison\n    sample_idx = 0\n    im1 = axes[2,0].imshow(real_samples[sample_idx], aspect='auto', cmap='viridis')\n    axes[2,0].set_title('Real EEG Sample')\n    axes[2,0].set_xlabel('Time')\n    axes[2,0].set_ylabel('Channels')\n    plt.colorbar(im1, ax=axes[2,0])\n    \n    im2 = axes[2,1].imshow(fake_samples[sample_idx], aspect='auto', cmap='viridis')\n    axes[2,1].set_title('Generated EEG Sample')\n    axes[2,1].set_xlabel('Time')\n    axes[2,1].set_ylabel('Channels')\n    plt.colorbar(im2, ax=axes[2,1])\n    \n    # 8. Correlation matrix\n    if len(real_samples) == len(fake_samples):\n        correlation_matrix = np.corrcoef(real_samples.reshape(len(real_samples), -1), \n                                       fake_samples.reshape(len(fake_samples), -1))\n        im3 = axes[2,2].imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n        axes[2,2].set_title('Real vs Generated Correlation Matrix')\n        plt.colorbar(im3, ax=axes[2,2])\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:50.777415Z","iopub.execute_input":"2025-09-23T22:11:50.777657Z","iopub.status.idle":"2025-09-23T22:11:50.792942Z","shell.execute_reply.started":"2025-09-23T22:11:50.777642Z","shell.execute_reply":"2025-09-23T22:11:50.792245Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def print_final_evaluation(evaluation_history):\n    \"\"\"\n    Print comprehensive final evaluation metrics\n    \"\"\"\n    if not evaluation_history:\n        print(\"No evaluation history available.\")\n        return\n    \n    final_metrics = evaluation_history[-1]['metrics']\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"ENHANCED GAN FINAL EVALUATION METRICS\")\n    print(\"=\"*60)\n    print(f\"Wasserstein Distance:         {final_metrics['wasserstein_distance']:.6f}\")\n    print(f\"KS Test Statistic:            {final_metrics['ks_statistic']:.6f} (p={final_metrics['ks_p_value']:.4e})\")\n    print(f\"Mean Difference:              {final_metrics['mean_diff']:.6f}\")\n    print(f\"Standard Deviation Diff:      {final_metrics['std_diff']:.6f}\")\n    print(f\"Skewness Difference:          {final_metrics['skewness_diff']:.6f}\")\n    print(f\"Kurtosis Difference:          {final_metrics['kurtosis_diff']:.6f}\")\n    \n    if 'mse' in final_metrics:\n        print(f\"Mean Squared Error:           {final_metrics['mse']:.6f}\")\n        print(f\"Root Mean Squared Error:      {final_metrics['rmse']:.6f}\")\n        print(f\"Mean Absolute Error:          {final_metrics['mae']:.6f}\")\n    \n    if 'correlation' in final_metrics:\n        print(f\"Pearson Correlation:          {final_metrics['correlation']:.4f} (p={final_metrics['correlation_p_value']:.4e})\")\n    \n    print(f\"Power Spectrum Difference:    {final_metrics['power_spectrum_diff']:.4f}\")\n    print(\"=\"*60)\n    \n    # Quality assessment\n    print(\"\\nQUALITY ASSESSMENT:\")\n    wass_dist = final_metrics['wasserstein_distance']\n    if wass_dist < 0.1:\n        print(\"ðŸŸ¢ EXCELLENT: Very similar distributions\")\n    elif wass_dist < 0.3:\n        print(\"ðŸŸ¡ GOOD: Reasonably similar distributions\")\n    elif wass_dist < 0.5:\n        print(\"ðŸŸ  MODERATE: Some differences in distributions\")\n    else:\n        print(\"ðŸ”´ NEEDS IMPROVEMENT: Significant distribution differences\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:52.322028Z","iopub.execute_input":"2025-09-23T22:11:52.322341Z","iopub.status.idle":"2025-09-23T22:11:52.328750Z","shell.execute_reply.started":"2025-09-23T22:11:52.322320Z","shell.execute_reply":"2025-09-23T22:11:52.328116Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def generate_enhanced_samples(generator, emotion_conditions, scaler_X, scaler_y, num_samples=100):\n    \"\"\"\n    Generate enhanced samples with proper scaling and evaluation\n    \"\"\"\n    generator.eval()\n    device = next(generator.parameters()).device\n    \n    with torch.no_grad():\n        # Normalize emotion conditions\n        emotion_normalized = scaler_y.transform(emotion_conditions)\n        emotion_tensor = torch.FloatTensor(emotion_normalized).to(device)\n        \n        # Generate noise\n        noise = torch.randn(num_samples, nz).to(device)\n        \n        # Generate samples\n        fake_data = generator(noise, emotion_tensor)\n        fake_data_np = fake_data.cpu().numpy()\n        \n        # Convert back to original scale\n        fake_data_original = scaler_X.inverse_transform(fake_data_np)\n        fake_data_shaped = fake_data_original.reshape(num_samples, 32, 90)\n    \n    return fake_data_shaped\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:53.530491Z","iopub.execute_input":"2025-09-23T22:11:53.530770Z","iopub.status.idle":"2025-09-23T22:11:53.535991Z","shell.execute_reply.started":"2025-09-23T22:11:53.530750Z","shell.execute_reply":"2025-09-23T22:11:53.535407Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# Main enhanced training function\ndef main_enhanced_gan_training(X, y):\n    \"\"\"\n    Main function for enhanced GAN training with comprehensive evaluation\n    \"\"\"\n    print(f\"Enhanced GAN Training - Data shape: X{X.shape}, y{y.shape}\")\n    \n    # Train the enhanced GAN\n    generator, discriminator, g_losses, d_losses, eval_history, scaler_X, scaler_y = train_improved_gan(\n        X, y, num_epochs=200, use_wgan_gp=True\n    )\n    \n    # Generate test samples\n    test_emotions = np.array([[5, 5, 5, 5], [7, 3, 6, 4], [2, 8, 3, 7]] * 20)  # 60 samples\n    generated_samples = generate_enhanced_samples(\n        generator, test_emotions, scaler_X, scaler_y, num_samples=len(test_emotions)\n    )\n    \n    # Create comprehensive visualizations\n    # Use a subset of real data for comparison\n    real_subset = X[:len(generated_samples)]\n    plot_comprehensive_results(g_losses, d_losses, eval_history, real_subset, generated_samples)\n    \n    # Print final evaluation\n    print_final_evaluation(eval_history)\n    \n    return generator, discriminator, generated_samples, scaler_X, scaler_y, eval_history\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:54.499863Z","iopub.execute_input":"2025-09-23T22:11:54.500685Z","iopub.status.idle":"2025-09-23T22:11:54.506353Z","shell.execute_reply.started":"2025-09-23T22:11:54.500654Z","shell.execute_reply":"2025-09-23T22:11:54.505566Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"\ngenerator, discriminator, fake_samples, scaler_X, scaler_y, evaluation = main_enhanced_gan_training(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T22:11:55.785399Z","iopub.execute_input":"2025-09-23T22:11:55.785669Z","iopub.status.idle":"2025-09-23T22:11:56.169498Z","shell.execute_reply.started":"2025-09-23T22:11:55.785650Z","shell.execute_reply":"2025-09-23T22:11:56.168496Z"}},"outputs":[{"name":"stdout","text":"Enhanced GAN Training - Data shape: X(1280, 32), y(1280, 4)\nTraining Enhanced GAN on data: X(1280, 32), y(1280, 4)\nGenerator parameters: 8,698,432\nDiscriminator parameters: 3,643,393\nStarting Enhanced GAN Training...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3738650049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_enhanced_gan_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/4153980421.py\u001b[0m in \u001b[0;36mmain_enhanced_gan_training\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Train the enhanced GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     generator, discriminator, g_losses, d_losses, eval_history, scaler_X, scaler_y = train_improved_gan(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_wgan_gp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     )\n","\u001b[0;32m/tmp/ipykernel_36/1223694202.py\u001b[0m in \u001b[0;36mtrain_improved_gan\u001b[0;34m(X, y, num_epochs, use_wgan_gp)\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0;31m# Wasserstein loss with gradient penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;31m# Real data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0;31m# Fake data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/4123937395.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, eeg_data, emotion_labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meeg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0;31m# run always called hooks if they have not already been run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36minner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m                 for hook_id, hook in (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x36 and 2884x1024)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x36 and 2884x1024)","output_type":"error"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}